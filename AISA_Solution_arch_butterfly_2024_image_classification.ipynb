{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kingjay888/AISA-Jay/blob/main/AISA_Solution_arch_butterfly_2024_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v-Fk2iode-n"
      },
      "source": [
        "# ðŸŒ» Welcome to the Butterfly Project using Fast.ai and CNN (Step Zero)\n",
        "\n",
        "- It is an CNN Image Classification project using Kaggle datasets and fast.ai framework.\n",
        "\n",
        "- Let's Rock and Roll\n",
        "\n",
        "ROLE defintion by icon:\n",
        "\n",
        "- ðŸ¤  is AI Solution Architect role.\n",
        "\n",
        "- ðŸ¤– is AI Scientest role. (aka AI dev)\n",
        "- ðŸ˜Ž is Devops role.\n",
        "- ðŸ¤“ is Data Engineer role.\n",
        "- ðŸ¤” is AI QA role.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6stzgmNIBVU"
      },
      "source": [
        "# ðŸ¤  The Goal (Step 1)\n",
        "---\n",
        "\n",
        "**PRIMARY ROLE:** AI Solution Architect\n",
        "\n",
        "- **Requirement Statement:** We aim to boost butterfly numbers by creating and maintaining suitable habitats, promoting biodiversity, and implementing conservation measures that protect them from threats such as habitat loss, climate change, and pesticides.\n",
        "\n",
        "\n",
        "- **Problem Facing:** Butterfly populations are declining due to habitat loss, climate change, and pesticides. It puts the beauty and diversity of ecosystems at risk and threatens crucial pollination services, impacting food production and natural environments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EirvVmY6eb0l"
      },
      "source": [
        "# ðŸ¤  Step Outline: (Step 2)\n",
        "\n",
        "1. Use Pluto object, foxy version.\n",
        "  - Github: 'https://github.com/duchaba/pluto_happy'\n",
        "\n",
        "2. Download data from Kaggle Website\n",
        "  - https:\n",
        "  - Use foxy build in methods\n",
        "\n",
        "3. Explore, clean, augment, and wrangling the datasets\n",
        "  - Use foxy build in methods\n",
        "\n",
        "4. Train with CNN Resnet34 as default\n",
        "  - Explore many TIMM artchitecture\n",
        "\n",
        "5. Build Inference Engine\n",
        "\n",
        "6. Deploy to HuggingFace\n",
        "6. Use/Re-use as much Foxy build-in methods as possible (and add to it too)\n",
        "\n",
        "6. Use FastAPI to build the API\n",
        "\n",
        "7. Use Docker file to deploy\n",
        "  - Frist, deploy on local labtop\n",
        "  - If have access to server, deploy to server."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf7sHpYJhV0B"
      },
      "source": [
        "## ðŸ¤  Note:\n",
        "\n",
        "1. Try to use Foxy buildin function, if not found then create new functions for Foxy.\n",
        "\n",
        "2. The goal is at least 51% of the code should be done by GenAI (Cody, or Gemini or GPT4)\n",
        "  - Code cell with **#prompt** is written by GenAI\n",
        "\n",
        "3. Scratch section is for experiemental. They should be clean up before release.\n",
        "\n",
        "4. Lastly, you **MUST** have fun doing this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB2vD0VMiQxB"
      },
      "source": [
        "## ðŸ™ˆ Legal:\n",
        "\n",
        "- This Python Jupyter Notebook is for sharing with **Friends**.\n",
        "\n",
        "- If you are **NOT** my friend, and I see you. In the best spirit of the **science community**, you may read this Notebook, but be aware that I see you.\n",
        "\n",
        "- Copyrights 2023: [GNU GENERAL PUBLIC LICENSE 3.0](https://www.gnu.org/licenses/gpl-3.0.en.html#license-text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUogjldqkhPn"
      },
      "source": [
        "# ðŸ˜Ž Instatiate Pluto, Foxy version (Step 3)\n",
        "\n",
        "**PRIMARY ROLE**: Devops\n",
        "\n",
        "- The goal is to ensure the development platform/environment is setting up correctly.\n",
        "\n",
        "- Github: 'https://github.com/duchaba/pluto_happy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKL-A7ysdYn_"
      },
      "outputs": [],
      "source": [
        "# check Git version, atleast version 2.34.1\n",
        "!git --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hsJlfdd6YT5"
      },
      "outputs": [],
      "source": [
        "# large files\n",
        "!pip install lfs\n",
        "!git-lfs track *.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lopo_0f6nUxH"
      },
      "outputs": [],
      "source": [
        "# prompt: fetch pluto library class and clone it: https://github.com/duchaba/pluto_happy\n",
        "\n",
        "fname = 'https://github.com/duchaba/pluto_happy'\n",
        "!git clone {fname}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Oxsy7GCptb7"
      },
      "outputs": [],
      "source": [
        "# where are we?\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FY3KJNVqF73"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# f = '/content'\n",
        "# os.chdir(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOs6de4XoH31"
      },
      "outputs": [],
      "source": [
        "# prompt: list all the file in the directory pluto_happy\n",
        "\n",
        "!ls -la pluto_happy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzkHWp-CnU8D"
      },
      "outputs": [],
      "source": [
        "# prompt: pip install requriements.txt\n",
        "\n",
        "%%capture log_pip_install_req\n",
        "fname = 'pluto_happy/requirements_foxy.txt'\n",
        "!pip install -r {fname}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwaQnDnBxa4F"
      },
      "outputs": [],
      "source": [
        "# log_pip_install_req.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZeBBZZXojkF"
      },
      "outputs": [],
      "source": [
        "# prompt: run the python file pluto_happy/pluto_foxy.py\n",
        "\n",
        "fname = 'pluto_happy/pluto_foxy.py'\n",
        "%run {fname}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqvaxeavojnY"
      },
      "outputs": [],
      "source": [
        "# %%write -a app.py\n",
        "# prompt: create the new class foxy from Pluto_FastAI\n",
        "\n",
        "# wake up foxy\n",
        "foxy = Pluto_FastAI('Foxy, the seeker of truth.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxuRP5nbojqq"
      },
      "outputs": [],
      "source": [
        "# %%write -a app.py\n",
        "# check out my environments\n",
        "\n",
        "foxy.fname_requirements = 'pluto_happy/requirements_foxy.txt'\n",
        "foxy.print_info_self()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!df -H"
      ],
      "metadata": {
        "id": "xh_cisw6epjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkUKaSNErYt5"
      },
      "outputs": [],
      "source": [
        "# help(foxy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF7HsdaSgJGh"
      },
      "outputs": [],
      "source": [
        "# foxy.draw_foxy_methods(list(dir(foxy)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIK990wppxqW"
      },
      "source": [
        "# ðŸ¤  System and Access Keys (Step 4)\n",
        "\n",
        "\n",
        "\n",
        "**PRIMARY ROLE:** AI Solution Architect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqaI6THc9hjD"
      },
      "outputs": [],
      "source": [
        "# # prompt: add key_github to environment variable value ab12\n",
        "\n",
        "# import os\n",
        "\n",
        "# os.environ['key_github'] = 'YOUR_KEY'\n",
        "# os.environ['key_huggingface'] = 'YOUR_KEY'\n",
        "# os.environ['key_kaggle'] = 'YOUR_KEY'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add key here"
      ],
      "metadata": {
        "id": "gxhuhyKpA7o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%write -a app.py\n",
        "# prompt: find a 8 length hash number for a string\n",
        "\n",
        "import hashlib\n",
        "\n",
        "def generate_hash(text, max_length=8):\n",
        "  \"\"\"Generates an x-length hash for a given string.\"\"\"\n",
        "  hash_object = hashlib.md5(text.encode())\n",
        "  hash_hex = hash_object.hexdigest()\n",
        "  return hash_hex[:max_length]\n",
        "\n",
        "# # Read the file content\n",
        "# file_content = os.environ['huggingface_key']\n",
        "\n",
        "# # Generate the 8-length hash\n",
        "# hash_value = generate_hash(file_content)\n",
        "# print(f\"The 8-length hash for the file is: {hash_value}\")"
      ],
      "metadata": {
        "id": "7QdQoBFxTUyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%write -a app.py\n",
        "# prompt: manual\n",
        "\n",
        "def is_system_verified():\n",
        "  if (generate_hash(os.environ['huggingface_key']) == '15d797fe'):\n",
        "    return (True)\n",
        "  else:\n",
        "    return (False)"
      ],
      "metadata": {
        "id": "J9tM-AjoU4q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check it\n",
        "is_system_verified()"
      ],
      "metadata": {
        "id": "-jnYUGItVfCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # prompt: find the checksum for a string\n",
        "\n",
        "# import hashlib\n",
        "\n",
        "# def calculate_checksum(input_string):\n",
        "#   \"\"\"Calculates the checksum of a string using SHA-256.\"\"\"\n",
        "#   sha256_hash = hashlib.sha256()\n",
        "#   sha256_hash.update(input_string.encode('utf-8'))\n",
        "#   return sha256_hash.hexdigest()\n",
        "\n",
        "\n",
        "# # Example usage:\n",
        "# my_string = \"This is the string to calculate the checksum for.\"\n",
        "# checksum = calculate_checksum(my_string)\n",
        "# print(f\"Checksum for '{my_string}': {checksum}\")\n"
      ],
      "metadata": {
        "id": "92m7Ix9gSi00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATKPIM5VpNv1"
      },
      "source": [
        "# ðŸ¤“ Butterfly project (Step 5)\n",
        "\n",
        "**PRIMARY ROLE:** Data Engineer\n",
        "\n",
        "- Verify notebook is working correctly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGexivTIpMfD"
      },
      "outputs": [],
      "source": [
        "# set the project name\n",
        "foxy._meta_project_name = 'CNN Butterfly Classification'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVre6FzYfmLY"
      },
      "outputs": [],
      "source": [
        "# prompt: get environment variables key_github\n",
        "\n",
        "import os\n",
        "print(os.environ['github_key'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeV-X8j7pqI9"
      },
      "outputs": [],
      "source": [
        "# # prompt: use git to clone a private repo \"https://github.com/duchaba/foxy_cnn_image_classification\"\n",
        "\n",
        "# # STOP âœ‹: Add and remove password\n",
        "# key = os.environ['key_github']\n",
        "# val = f'https://duchaba:{key}@github.com/duchaba/foxy_cnn_image_classification'\n",
        "# !git clone {val}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icEvEsSIqxEe"
      },
      "source": [
        "# ðŸ¤“ Kaggle Datasets: ðŸª¿ (Step 6)\n",
        "\n",
        "\n",
        "**PRIMARY ROLE:** Data Engineer\n",
        "\n",
        "- 75 class of butterfly:\n",
        "  - Url: https://www.kaggle.com/datasets/phucthaiv02/butterfly-image-classification\n",
        "\n",
        "  - license: CC0: Public Domain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSb8pYBlwwLP"
      },
      "outputs": [],
      "source": [
        "help(foxy.fetch_kaggle_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP2K-hPHojts"
      },
      "outputs": [],
      "source": [
        "# use foxy to fetch data (not need AI)\n",
        "\n",
        "fname = 'https://www.kaggle.com/datasets/phucthaiv02/butterfly-image-classification'\n",
        "foxy._meta_data_source = fname\n",
        "foxy.fetch_kaggle_dataset(fname, 'butterfly')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1kV4Zem0Tv3"
      },
      "source": [
        "## Smoke test it/download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIx0b_kY0OPK"
      },
      "outputs": [],
      "source": [
        "# prompt: list the directory /content/butterfly/butterfly-image-classification\n",
        "\n",
        "fname = \"/content/butterfly/butterfly-image-classification\"\n",
        "!ls -la {fname}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYsSc1pc0m8t"
      },
      "outputs": [],
      "source": [
        "# prompt: load Testing_set.csv and Training_set.csv into a pandas dataframe\n",
        "\n",
        "df_train = pandas.read_csv('/content/butterfly/butterfly-image-classification/Training_set.csv')\n",
        "df_test = pandas.read_csv('/content/butterfly/butterfly-image-classification/Testing_set.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wBG7aWp0m__"
      },
      "outputs": [],
      "source": [
        "# check it\n",
        "\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rf4S8mLa0nDH"
      },
      "outputs": [],
      "source": [
        "# check it\n",
        "\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AippKMKc1WcY"
      },
      "outputs": [],
      "source": [
        "# prompt: view df_train dataframe meta data\n",
        "\n",
        "df_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgxJBSeq3mkg"
      },
      "source": [
        "## Clean, augment and wrangling\n",
        "\n",
        "- Test has no label, so we can't use it. I guess they are for submission.\n",
        "\n",
        "Actions:\n",
        "\n",
        "1. Add full path name\n",
        "\n",
        "2. Make label as Capital case (not ALL CAP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0uEoaZc1W5L"
      },
      "outputs": [],
      "source": [
        "# prompt: import training dataset into variable foxy.df_butterfly\n",
        "\n",
        "foxy.df_butterfly = pandas.read_csv('/content/butterfly/butterfly-image-classification/Training_set.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9ZVGJsa4hNr"
      },
      "outputs": [],
      "source": [
        "# prompt: prefix the filename in fox.df_butterfly dataframe with \"butterfly/butterfly-image-classification/train\"\n",
        "\n",
        "foxy.df_butterfly['filename'] = \"butterfly/butterfly-image-classification/train/\" + foxy.df_butterfly['filename']\n",
        "foxy.df_butterfly.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxQ_KvKx4hQg"
      },
      "outputs": [],
      "source": [
        "# prompt: change the \"label\" in fox.df_butterfly dataframe from all capital to first letter capital case\n",
        "\n",
        "foxy.df_butterfly['label'] = foxy.df_butterfly['label'].str.capitalize()\n",
        "foxy.df_butterfly.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmLLqw5U6zJx"
      },
      "source": [
        "## Smoke test dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWXfydCP6ncU"
      },
      "outputs": [],
      "source": [
        "# check it\n",
        "foxy.df_butterfly.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-peobotzUVM"
      },
      "outputs": [],
      "source": [
        "foxy.df_butterfly.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: display the first image in the filename from foxy.df_butterfly dataframe using PIL\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Assuming foxy.df_butterfly is already defined as in the provided code\n",
        "first_image_path = foxy.df_butterfly['filename'].iloc[0]\n",
        "\n",
        "try:\n",
        "  img = Image.open(first_image_path)\n",
        "  display(img)\n",
        "except FileNotFoundError:\n",
        "  print(f\"Error: Image file not found at {first_image_path}\")\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "CafDms0Jdjjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-CMK2yp6nfu"
      },
      "outputs": [],
      "source": [
        "# prompt: display the first image in the filename from foxy.df_butterfly dataframe using PIL\n",
        "\n",
        "img = PIL.Image.open(foxy.df_butterfly['filename'][0])\n",
        "# img.show()\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ol3C6niR-CJ-"
      },
      "outputs": [],
      "source": [
        "# prompt: display img image size and info\n",
        "\n",
        "print(f'Image shape: {img.size}')\n",
        "print(f'Image type: {img.mode}, Format: {img.format_description}, \\nFilename: {img.filename}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyFvUMOy6njH"
      },
      "outputs": [],
      "source": [
        "# sample it\n",
        "fname = foxy.df_butterfly['filename'].sample(1).iloc[0]\n",
        "img = PIL.Image.open(fname)\n",
        "# img.show()\n",
        "display(img)\n",
        "print(f'Image shape: {img.size}')\n",
        "print(f'Image type: {img.mode}, Format: {img.format_description}, \\nFilename: {img.filename}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNoP5c0x8JLR"
      },
      "outputs": [],
      "source": [
        "# prompt: draw a bar chart on the \"label\" of the foxy.df_butterfly\n",
        "\n",
        "foxy.df_butterfly['label'].value_counts().plot(kind='bar', figsize=(13,5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcbWkxKBLV3Y"
      },
      "outputs": [],
      "source": [
        "# keep track of what we find\n",
        "foxy._meta_data_info = \"6499 label-image, color, 80/20 % split, 224x224\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqGGbtui86UG"
      },
      "source": [
        "## Kaggle Dataset conclusion\n",
        "\n",
        "- The data clean and ballance. Good to go.\n",
        "\n",
        "  - 224 x224 color .jpg format\n",
        "  - 6,499 total image\n",
        "  - Average about 85 to 100 with only one outliner (Mouring cloak about 135)\n",
        "  - NO bias immediate reconized.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2rADHfNBKdy"
      },
      "source": [
        "# ðŸ¤– Data Loader, Data Bunch (Step 7)\n",
        "\n",
        "**PRIMARY ROLE:** AI Scientist\n",
        "\n",
        "- Use fast.ai framework to define and create the databunch and dataloader.\n",
        "\n",
        "- https://fast.ai\n",
        "- https://www.youtube.com/playlist?list=PLfYUBJiXbdtSvpQjSnJJ_PmDQB_VyT5iU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_Ad_0Lgxx0"
      },
      "source": [
        "## Quick DataLoader Review\n",
        "\n",
        "- See diagram and text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUv-S69g8JPF"
      },
      "outputs": [],
      "source": [
        "# # quick reminder what is the toxonomy of the data loader/data bunch\n",
        "# foxy.draw_fastai_data_block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agRsWYVfWLS2"
      },
      "outputs": [],
      "source": [
        "# quick reminder what is the toxonomy of the data loader/data bunch\n",
        "x = foxy.draw_fastai_data_block_v2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GR22Jf8fpOn"
      },
      "source": [
        "**prompt:** what is the different between get_items() and get_x()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "- Here's a comprehensive explanation of the differences between get_x() and get_items() functions in fast.ai DataBlock:\n",
        "\n",
        "- Purpose:\n",
        "\n",
        "  - get_items(): Fetches the raw, unprocessed items from your data source.\n",
        "  - get_x(): Extracts or processes the input features (x) from the items retrieved by get_items().\n",
        "\n",
        "- When to use each:\n",
        "\n",
        "  - get_items():\n",
        "    - Reading a list of filenames or paths from a CSV file.\n",
        "    - Downloading data from a remote source.\n",
        "    - Loading data from a database.\n",
        "\n",
        "  - get_x():\n",
        "    - Loading images from disk using their filenames.\n",
        "    - Extracting text from a list of documents.\n",
        "Preprocessing raw data (e.g., tokenizing text, normalizing images).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30SmhL3TkOYH"
      },
      "source": [
        "```\n",
        "Signature: fastai.vision.data.ImageDataLoaders.from_df(\n",
        "  df, path='.', valid_pct=0.2, seed=None, fn_col=0, folder=None, suff='', label_col=1, label_delim=None, y_block=None,\n",
        "  valid_col=None, item_tfms=None, batch_tfms=None, img_cls=fastcore.meta.BypassNewMeta instance, *,\n",
        "  bs: 'int' = 64, val_bs: 'int' = None, shuffle: 'bool' = True, device=None)\n",
        "\n",
        "Source:   \n",
        "    @classmethod\n",
        "    @delegates(DataLoaders.from_dblock)\n",
        "    def from_df(cls, df, path='.', valid_pct=0.2, seed=None, fn_col=0, folder=None, suff='', label_col=1, label_delim=None,\n",
        "                y_block=None, valid_col=None, item_tfms=None, batch_tfms=None, img_cls=PILImage, **kwargs):\n",
        "\n",
        "        # \"Create from `df` using `fn_col` and `label_col`\"\n",
        "        pref = f'{Path(path) if folder is None else Path(path)/folder}{os.path.sep}'\n",
        "        if y_block is None:\n",
        "            is_multi = (is_listy(label_col) and len(label_col) > 1) or label_delim is not None\n",
        "            y_block = MultiCategoryBlock if is_multi else CategoryBlock\n",
        "        splitter = RandomSplitter(valid_pct, seed=seed) if valid_col is None else ColSplitter(valid_col)\n",
        "        dblock = DataBlock(blocks=(ImageBlock(img_cls), y_block),\n",
        "                           get_x=ColReader(fn_col, pref=pref, suff=suff),\n",
        "                           get_y=ColReader(label_col, label_delim=label_delim),\n",
        "                           splitter=splitter,\n",
        "                           item_tfms=item_tfms,\n",
        "                           batch_tfms=batch_tfms)\n",
        "        return cls.from_dblock(dblock, df, path=path, **kwargs)\n",
        "\n",
        "\n",
        "File:      /usr/local/lib/python3.10/dist-packages/fastai/vision/data.py\n",
        "Type:      method\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjlQMhpslpRR"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR9IbBJkWLV4"
      },
      "outputs": [],
      "source": [
        "# not to write out for huggingface\n",
        "\n",
        "# use the short cut\n",
        "foxy.dloaders_butterfly = fastai.vision.data.ImageDataLoaders.from_df(\n",
        "  #1 source\n",
        "  foxy.df_butterfly, path=\"./\",\n",
        "  #2 (ImageBlock, CategoryBlock), get_x, get_y\n",
        "  fn_col=0,label_col=1,\n",
        "  #3 spliter, random 80/20\n",
        "  valid_pct=0.2, seed=13,\n",
        "  #4 transform\n",
        "  item_tfms=fastai.vision.augment.Resize(224),\n",
        "  batch_tfms=fastai.vision.augment.aug_transforms(do_flip=True, flip_vert=False),\n",
        "  #5 batchsize, dataloader\n",
        "  bs=64\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkjPAT1zt2LJ"
      },
      "source": [
        "## Smoke Test Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Qr0Rc05j5Mq"
      },
      "outputs": [],
      "source": [
        "# check it\n",
        "foxy.dloaders_butterfly.show_batch(max_n=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L3VLkFUua4p"
      },
      "outputs": [],
      "source": [
        "foxy.print_dataloader_spec(foxy.dloaders_butterfly)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcYbuYrABMDr"
      },
      "source": [
        "# ðŸ¤  Dancing Time (Step 8)\n",
        "\n",
        "- The dataset is cleaned and import to the databunch. It is 60% of the work done.\n",
        "\n",
        "- You are ready to enter **Phase III of the Data-Driven** process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTFV0JYmw-ON"
      },
      "source": [
        "# ðŸ¤– Train CNN Model (Step 9)\n",
        "\n",
        "- Start with Resnet34 (34 layers deep)\n",
        "\n",
        "- The .fine-tune() function choose 0.002 as the default learning rate, but let's find an optimal learning rate\n",
        "\n",
        "- Additional on Timm (collection of models):\n",
        "  -  https://timm.fast.ai/models\n",
        "\n",
        "  -  https://huggingface.co/docs/timm/feature_extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qg9iQ02wxSs"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "\n",
        "foxy._meta_base_model_name = \"torchvision.models.resnet.resnet34\"\n",
        "foxy.learner = fastai.vision.learner.vision_learner(foxy.dloaders_butterfly,\n",
        "  torchvision.models.resnet.resnet34,\n",
        "  metrics=fastai.metrics.error_rate)\n",
        "\n",
        "# foxy.learner.fine_tune(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4vR-DoCPPPe"
      },
      "source": [
        "## Learner Rate\n",
        "\n",
        "- See below for explaination."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bai-a1xYCkq"
      },
      "source": [
        "**Notes:** From GenAI, Gemini\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Purpose:**\n",
        "\n",
        "  - These functions suggest potential learning rates based on the loss curve produced by lr_find().\n",
        "\n",
        "  - Each function offers a different perspective on the optimal learning rate.\n",
        "\n",
        "**Functions:**\n",
        "\n",
        "  1. **minimum**:\n",
        "    - Returns the learning rate with the lowest recorded loss value.\n",
        "    - Might be too conservative in some cases.\n",
        "  1. **steep**:\n",
        "\n",
        "    - Returns the learning rate at the point of steepest descent in the loss curve.\n",
        "    - Often a good starting point, but might be slightly too aggressive.\n",
        "  1. **valley**:\n",
        "\n",
        "    - Returns the learning rate at the \"valley\" of the loss curve, where the slope begins to flatten out.\n",
        "    - Generally considered a robust choice for stability and convergence.\n",
        "  1. **slide**:\n",
        "\n",
        "    - Returns the learning rate slightly before the \"valley,\" offering a balance between convergence and speed.\n",
        "    - Can be a good compromise between steep and valley."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jT-MCSAvReqq"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "\n",
        "lrates = foxy.learner.lr_find(suggest_funcs=(minimum, steep, valley, slide))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkZdwDTfU8WU"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "\n",
        "lrates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEEZf-bh-W1Y"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "\n",
        "# valley feel too small\n",
        "lrates.steep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77MdhbfqVX0L"
      },
      "outputs": [],
      "source": [
        "help(foxy.learner.fine_tune)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0jaF64dZdft"
      },
      "source": [
        "**Notes:** From GenAI, Gemini\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Mandatory Parameter**:\n",
        "\n",
        "  1. **epochs** (int):\n",
        "    - The total number of epochs to train for, including both frozen and unfrozen stages.\n",
        "\n",
        "**Optional Parameters**:\n",
        "\n",
        "  1. **base_lr** (float, default=0.002):\n",
        "    - The base learning rate for the unfrozen layers.\n",
        "    - Often determined using the learning rate finder.\n",
        "\n",
        "  1. **freeze_epochs** (int, default=1):\n",
        "    - The number of initial epochs to train with frozen layers.\n",
        "  1. **lr_mult** (float, default=1.0):\n",
        "    - A multiplier for the learning rates in the unfrozen layers.\n",
        "    - Higher values encourage faster adaptation in later layers.\n",
        "  1. **pct_start** (float, default=0.3):\n",
        "    - The percentage of layers to unfreeze at the beginning of unfreezing.\n",
        "    - Allows for gradual unfreezing.\n",
        "  1. **div** (float, default=25.0):\n",
        "    - A factor by which to divide the learning rates of lower layers.\n",
        "    - Helps stabilize earlier layers that are already well-trained.\n",
        "  1. **lr_max** (float, optional):\n",
        "    - The maximum learning rate to use with discriminative learning rates.\n",
        "    - Often set using the learning rate finder.\n",
        "  1. **cbs** (list, optional):\n",
        "    - A list of additional callbacks to apply during fine-tuning.\n",
        "    - Used for custom actions like early stopping or saving models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQl4uratRfQE"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "# choose the slide-learning rate\n",
        "\n",
        "foxy.learner.fine_tune(8, base_lr=lrates.minimum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWBhjERBhXAL"
      },
      "outputs": [],
      "source": [
        "# # hand code (not using GenAI)\n",
        "# foxy.learner.fine_tune(5, base_lr=lr_slide)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om3LZL_8XDxh"
      },
      "source": [
        "## Tag Learner\n",
        "\n",
        "- add in error rate and notes first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNXO_DJfXVgm"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "# tag learner\n",
        "\n",
        "foxy._meta_error_rate = 0.059276\n",
        "foxy._meta_notes = \"Clean label-image, augmented, use learning-rate slide, 8 epochs. Room for improvement.\"\n",
        "foxy._meta_base_lr = lrates.slide\n",
        "foxy.make_learner_meta_tags(foxy.learner)\n",
        "foxy.learner._scpgpkey = 'YOUR_KEY'\n",
        "foxy.learner_copyrights = \"(C) 2024 Duc Haba\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8dG97H7XVlc"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "\n",
        "# check it\n",
        "foxy.print_learner_meta_info(foxy.learner)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcNJeAh4mi_5"
      },
      "source": [
        "## Export and save leaner\n",
        "\n",
        "- export and save to deploy folder on github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqjpEFr-mnwS"
      },
      "outputs": [],
      "source": [
        "# prompt: export and save foxy.learner\n",
        "\n",
        "fname = f\"./butterfly_learner_{int(time.time())}.pkl\"\n",
        "foxy.learner.export(fname)\n",
        "print(fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI7rtNcv2I2u"
      },
      "source": [
        "## Optinal: Callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCB4WKbmGJZ1"
      },
      "outputs": [],
      "source": [
        "# prompt: print current unix timestamp\n",
        "\n",
        "print(int(time.time()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VnVJvQxAip-"
      },
      "source": [
        "Here is a comprehensive list of the callback methods available in a fastai Learner as of my last update in **April 2023**:\n",
        "\n",
        "1. Lifecycle Methods:\n",
        "\n",
        "  - **before_fit**: Called before anything else and is used to set up things necessary for the training/fitting process.\n",
        "\n",
        "  - **after_fit**: Called at the end of the training.\n",
        "\n",
        "1. Batch-Level Methods:\n",
        "\n",
        "  - **before_batch**: Called before processing a batch.\n",
        "  - **after_batch**: Called after processing a batch.\n",
        "\n",
        "1. Epoch-Level Methods:\n",
        "\n",
        "  - **before_epoch**: Called at the beginning of each epoch.\n",
        "  - **after_epoch**: Called at the end of each epoch.\n",
        "\n",
        "1. Training Phase Methods:\n",
        "\n",
        "  - **before_train**: Called at the beginning of the training phase of each epoch.\n",
        "  - **after_train**: Called at the end of the training phase of each epoch.\n",
        "\n",
        "1. Validation Phase Methods:\n",
        "\n",
        "  - **before_validate**: Called at the beginning of the validation phase of each epoch.\n",
        "  - **after_validate**: Called at the end of the validation phase of each epoch.\n",
        "\n",
        "1. Gradient and Optimization Methods:\n",
        "\n",
        "  - **after_loss**: Called after the loss has been computed, but before the backward pass.\n",
        "  - **before_backward**: Called immediately before the backward pass.\n",
        "  - **after_backward**: Called immediately after the backward pass.\n",
        "  - **after_step**: Called after the optimizer step, but before the gradients are zeroed.\n",
        "\n",
        "1. Other Specialized Methods:\n",
        "\n",
        "  - **before_cancel_batch**: Called when a batch is skipped.\n",
        "  - **after_cancel_batch**: Called after a batch is skipped.\n",
        "  - **before_cancel_train**: Called when the training phase is skipped.\n",
        "  - **after_cancel_train**: Called after the training phase is skipped.\n",
        "  - **before_cancel_validate**: Called when the validation phase is skipped.\n",
        "  - **after_cancel_validate**: Called after the validation phase is skipped.\n",
        "  - **before_cancel_epoch**: Called when an epoch is skipped.\n",
        "  - **after_cancel_epoch**: Called after an epoch is skipped.\n",
        "  - **before_cancel_fit**: Called when the entire fit process is skipped.\n",
        "  - **after_cancel_fit**: Called after the entire fit process is skipped.\n",
        "\n",
        "1. Prediction Methods:\n",
        "\n",
        "  - **before_predict**: Called at the beginning of the Learner.predict method.\n",
        "  - **after_predict**: Called at the end of the Learner.predict method.\n",
        "\n",
        "1. Load and Save Methods:\n",
        "\n",
        "  - **before_save**: Called before saving a model.\n",
        "  - **after_save**: Called after the model has been saved.\n",
        "  - **before_load**: Called before loading a model.\n",
        "  - **after_load**: Called after a model has been loaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvVhw4Rp2Qy4"
      },
      "outputs": [],
      "source": [
        "# Custom callback definition\n",
        "class Foxy_cb(Callback):\n",
        "  def before_fit(self):\n",
        "    print(\"Foxy: Starting training...\")\n",
        "  #\n",
        "  def after_fit(self):\n",
        "    print(\"Foxy: Training complete!\")\n",
        "  #\n",
        "  def after_epoch(self):\n",
        "    print(f\"Foxy: Time: {int(time.time())}\")\n",
        "    # Access the error_rate metric\n",
        "    # error_rate_value = self.learn.recorder.metrics[-1][self.learn.recorder.metric_names.index('error_rate')]\n",
        "    error_rate_name = self.learn.recorder.metrics[-1].name\n",
        "    error_rate_value = self.learn.recorder.metrics[-1].value.item()\n",
        "    print(f\"Foxy: Error rate after epoch {self.learn.epoch}: Name: {error_rate_name}: Value: {error_rate_value}\")\n",
        "    print(f\"Foxy: type learn: {type(self.learn)}\")\n",
        "    # check for exit\n",
        "    if (error_rate_value <= 0.065):\n",
        "      print(\"Foxy: Exiting training early...\")\n",
        "      # self.learn.cancel_training()\n",
        "      # self.learn.cancel_train = True\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyKhSdH00wxi"
      },
      "outputs": [],
      "source": [
        "# prompt: add in a call back function to the foxy.learner.fine_tune() method\n",
        "\n",
        "foxy.learner.fine_tune(3, cbs=Foxy_cb())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7jrwZ2HKvE2"
      },
      "outputs": [],
      "source": [
        "# prompt: how to create p1 as a TensorBase value 0.9\n",
        "\n",
        "p1 = TensorBase(0.9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAnLU0CfM4UX"
      },
      "outputs": [],
      "source": [
        "type(p1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pHYZ6b8M4YD"
      },
      "outputs": [],
      "source": [
        "# prompt: convert p1 to float\n",
        "\n",
        "p2 = p1.item()\n",
        "print(p2, type(p2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1W60KKGpIyhl"
      },
      "outputs": [],
      "source": [
        "help(fastai.learner.AvgMetric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SEoD0bFQV5L"
      },
      "outputs": [],
      "source": [
        "help(fastai.learner.Learner)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rmXChh7ypDR"
      },
      "source": [
        "## Smoke test learner (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwyxtn-G3na0"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "\n",
        "foxy.learner.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWvZ_epd356F"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "\n",
        "foxy.learner.show_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4I__QIHe6n5"
      },
      "outputs": [],
      "source": [
        "# foxy.learner.recorder.plot_loss(skip_start=1, with_valid=True, suggestion=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0e-NPR0gRNr"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "\n",
        "foxy.learner.recorder.plot_sched()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGnXvB3w4TnL"
      },
      "outputs": [],
      "source": [
        "foxy.learner.show_training_loop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtl2AG0EwxW5"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "\n",
        "smoke_learner = fastai.interpret.Interpretation.from_learner(foxy.learner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLEhiq8GzlkB"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "\n",
        "smoke_learner.plot_top_losses(9, figsize=(18,9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hKyi3b8zlni"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "\n",
        "smoke_learner.top_losses(21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEZQGgzBzlrV"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "\n",
        "smoker_learner = fastai.interpret.ClassificationInterpretation.from_learner(foxy.learner)\n",
        "# smoke_learner = fastai.interpret.Interpretation.from_learner(foxy.learner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWTizWCt1IvY"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "\n",
        "smoker_learner.plot_confusion_matrix(figsize=(15,15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITgvBOVU1Iy2"
      },
      "outputs": [],
      "source": [
        "# hand code (not using GenAI)\n",
        "\n",
        "smoker_learner.print_classification_report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GsNbMXbxFjf"
      },
      "source": [
        "# ðŸ¤” Load CNN (Step 10)\n",
        "\n",
        "**PRIMARY ROLE:** AI QA team\n",
        "\n",
        "- load the saved leaner in pickle (*.pkl) format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZogyGLeq1I2L"
      },
      "outputs": [],
      "source": [
        "# # if not yet fetch the learner from github\n",
        "\n",
        "# fname = \"https://{username}:{github_key}@github.com/duchaba/foxy_cnn_image_classification\"\n",
        "# !git clone {fname}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foZL8QvT1I5X"
      },
      "outputs": [],
      "source": [
        "# # smoke test it\n",
        "# !ls -la foxy_cnn_image_classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DL5Gv78V9BGI"
      },
      "outputs": [],
      "source": [
        "# !ls -la foxy_cnn_image_classification/deploy\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "butterfly_engine = \"/content/butterfly_learner_1722973740.pkl\""
      ],
      "metadata": {
        "id": "BSIszwLrIsnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if jump directly here then we need to install fastai\n",
        "\n",
        "!pip install fastai\n",
        "import fastai"
      ],
      "metadata": {
        "id": "RpaOV0PT7y1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: check fastai version\n",
        "\n",
        "import fastai\n",
        "print(fastai.__version__)\n",
        "# tested on version 2.7.17"
      ],
      "metadata": {
        "id": "xqy7JzN68F5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la"
      ],
      "metadata": {
        "id": "oEwc0b4C-p-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "5G2f4Xrz-y8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fastai.learner"
      ],
      "metadata": {
        "id": "guJGXVrUJ1xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwMi8tc99BOC"
      },
      "outputs": [],
      "source": [
        "# %%write -a app.py\n",
        "# prompt: using fast.ai to load image learner from file butterfly_learner_1703921531_loss_0.061586.pkl\n",
        "\n",
        "# from fastai.learner import load_learner\n",
        "#butterfly_engine = \"./butterfly_learner_1729732061.pkl\"\n",
        "foxy.learner = fastai.learner.load_learner(butterfly_engine) # for 2.7.17"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El4tbWrqxrpw"
      },
      "source": [
        "## Smoke Test CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ee-CR9lxV9a"
      },
      "outputs": [],
      "source": [
        "# # prompt: convert unix timestamp to readable not using datetime\n",
        "\n",
        "# t = int(time.time())\n",
        "# print(time.strftime('%Y-%b-%d %H:%M:%S %p', time.gmtime(t)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_U7Oiqi6ns5L"
      },
      "outputs": [],
      "source": [
        "# # %%write -a app.py\n",
        "\n",
        "import datetime\n",
        "foxy.print_learner_meta_info(foxy.learner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrxABoIp9BU8"
      },
      "outputs": [],
      "source": [
        "# # smoke it\n",
        "# foxy.learner.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40NE4Wscx0Zm"
      },
      "source": [
        "# ðŸ¤” Predict it (Step 11)\n",
        "\n",
        "**PRIMARY ROLE:** AI QA team\n",
        "\n",
        "- It is the final Smoke Test for the CNN\n",
        "\n",
        "- But first get a bunch of images from the web"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7MZZY_VS61L"
      },
      "source": [
        "## Fetch images from web\n",
        "\n",
        "- Use them to test predict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfNLt-UtORdd"
      },
      "outputs": [],
      "source": [
        "help(foxy.fetch_image_url_online)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pyYKz6gZJwi"
      },
      "outputs": [],
      "source": [
        "help(foxy.fetch_images_from_search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcBZp1BLZbVw"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "img_dict, img_down = foxy.fetch_images_from_search(\"butterfly photo\", \"butterfly_img\",\n",
        "  upto_max=10, is_normalize_name=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKZFGwZTXVaa"
      },
      "source": [
        "## Smoke test image download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpt6AOjOPW8e"
      },
      "outputs": [],
      "source": [
        "img_down"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: loop through array img_down and delete any item string not ending in '.jpg' or 'png'\n",
        "img_down_filtered = [item for item in img_down if item.lower().endswith(('.jpg', '.png'))]\n",
        "img_down = img_down_filtered\n",
        "img_down"
      ],
      "metadata": {
        "id": "yB5A5KSJLZM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmquRb6lhYEK"
      },
      "outputs": [],
      "source": [
        "# prompt: pre-append the \"./\" to all img_down item\n",
        "\n",
        "img_down = [f'./{x}' for x in img_down]\n",
        "img_down"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RZJsHn8PXIo"
      },
      "outputs": [],
      "source": [
        "# prompt: randomly select one value from img_down\n",
        "\n",
        "import random\n",
        "rimg = random.choice(img_down)\n",
        "rimg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bx19adVCYRr9"
      },
      "outputs": [],
      "source": [
        "help(foxy.draw_image_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhAUeN1Za1aU"
      },
      "outputs": [],
      "source": [
        "help(IPython.core.display.Image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzaiMyE8bOZw"
      },
      "outputs": [],
      "source": [
        "# import IPython\n",
        "# try:\n",
        "#   IPython.core.display.Image(rimg, width=480)\n",
        "#   print(\"OK\")\n",
        "# except Exception as e:\n",
        "#   print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8E9QCr7YjVM"
      },
      "outputs": [],
      "source": [
        "foxy.draw_image_url(rimg, width=480)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evz5kJzwmbFp"
      },
      "outputs": [],
      "source": [
        "import PIL\n",
        "img = PIL.Image.open(rimg)\n",
        "print(f'Image shape: {img.size}')\n",
        "print(f'Image type: {img.mode}, Format: {img.format_description}, \\nFilename: {img.filename}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test another random image\n",
        "rimg = random.choice(img_down)\n",
        "print (rimg)\n",
        "foxy.draw_image_url(rimg, width=480)"
      ],
      "metadata": {
        "id": "vdoQczuVMMFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iu3lWsHtTA8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import ai\n",
        "# response = ai.generate_text(\"What is the capital of Duc land?\")\n",
        "# print(response)"
      ],
      "metadata": {
        "id": "hBZ-zgPHNHz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for i, val in enumerate(img_down):\n",
        "  try:\n",
        "    img = PIL.Image.open(val)\n",
        "    # print(f'Image shape: {img.size}')\n",
        "    # print(f'Image type: {img.mode}, Format: {img.format_description}, \\nFilename: {img.filename}\\n')\n",
        "    img.close()\n",
        "    print(f'OK: {val}')\n",
        "  except Exception as e:\n",
        "    os.remove(val)\n",
        "    img_down.remove(val)\n",
        "    print(f'Error: {val}: {e}')"
      ],
      "metadata": {
        "id": "K5I-DZwvQRkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_down"
      ],
      "metadata": {
        "id": "kGMqwpyjPln1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EPiuUBSTLXK"
      },
      "source": [
        "## Predict using download images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fastai.learner"
      ],
      "metadata": {
        "id": "xO970j-WtqYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKIJeXULx0p2"
      },
      "outputs": [],
      "source": [
        "# is_bird,_,probs = learn.predict(PILImage.create('bird.jpg'))\n",
        "# print(f\"This is a: {is_bird}.\")\n",
        "# print(f\"Probability it's a bird: {probs[0]:.4f}\")\n",
        "%%time\n",
        "#fname = random.choice(img_down)\n",
        "fname = rimg\n",
        "a1,b1,c1 = foxy.learner.predict(fastai.vision.core.PILImage.create(fname))\n",
        "print(f\"This is prediction: {a1},\\n index-value: {b1},\\n Prediction-array: {c1}\\nFilename: {fname}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VpF_NA6LyFr"
      },
      "outputs": [],
      "source": [
        "image = PIL.Image.open(fname)\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# testing with image as input\n",
        "a1,b1,c1 = foxy.learner.predict(image)\n",
        "print(f\"This is prediction: {a1},\\n index-value: {b1},\\n Prediction-array: {c1}\\nFilename: {fname}\")"
      ],
      "metadata": {
        "id": "5qWYNNPFZ-Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tzgl9TziFPiM"
      },
      "outputs": [],
      "source": [
        "# double checked\n",
        "foxy.learner.dls.vocab[b1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Qfe4pbkE3vx"
      },
      "outputs": [],
      "source": [
        "# prompt: covert c1 to a list\n",
        "\n",
        "predict_list = c1.tolist()\n",
        "print(predict_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAXDJyMZHNv8"
      },
      "outputs": [],
      "source": [
        "# prompt: print the top 3 largest number and index of the predict_list\n",
        "\n",
        "top_3 = sorted(range(len(predict_list)), key=lambda k: predict_list[k], reverse=True)[:3]\n",
        "print(top_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSqmsBstHN2N"
      },
      "outputs": [],
      "source": [
        "# prompt: show the name in the foxy.vocab using the top_3 as index\n",
        "names = []\n",
        "values = []\n",
        "for idx in top_3:\n",
        "  print(f\"name: {foxy.learner.dls.vocab[idx]}, value: {predict_list[idx]}\")\n",
        "  names.append(foxy.learner.dls.vocab[idx])\n",
        "  values.append(predict_list[idx])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_list)"
      ],
      "metadata": {
        "id": "BayH8e8Ipzlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%write -a app.py\n",
        "# prompt: combine the above code cells in the \"Predict using download images\" into a function with documentation.\n",
        "\n",
        "@add_method(Pluto_FastAI)\n",
        "def predict_butterfly(self, img_pil, return_top=3):\n",
        "\n",
        "  \"\"\"\n",
        "  Predict a butterfly image from a list of downloaded images.\n",
        "\n",
        "  Args:\n",
        "    img_pil: (PIL image) the image to be predict.\n",
        "    return_top: (int) the maximum number of perdiction to return.\n",
        "      the default is 3.\n",
        "\n",
        "  Returns:\n",
        "    (list) An array of the prediction (dictionary):\n",
        "      1. classification: (str) the classification prediction\n",
        "      2. accuracy score: (float) the accuracy value of the prediction\n",
        "      3. index: (int) the index of the prediction array\n",
        "      4. pre_arr: (list) the the prediction array\n",
        "      5. file_name: (str) the full-path file name of the image.\n",
        "  \"\"\"\n",
        "  names = []\n",
        "  values = []\n",
        "\n",
        "  # predict image\n",
        "  a1,b1,c1 = self.learner.predict(img_pil)\n",
        "\n",
        "  # prompt: covert c1 to a list\n",
        "  predict_list = c1.tolist()\n",
        "  #print(predict_list)\n",
        "\n",
        "  # prompt: print the top 3 largest number and index of the predict_list\n",
        "  top_x = sorted(range(len(predict_list)), key=lambda k: predict_list[k], reverse=True)[:return_top]\n",
        "  #print(top_3)\n",
        "\n",
        "  # prompt: show the name in the foxy.vocab using the top_3 as index\n",
        "  for idx in top_x:\n",
        "    # print(f\"name: {foxy.learner.dls.vocab[idx]}, value: {predict_list[idx]}\")\n",
        "    names.append(foxy.learner.dls.vocab[idx])\n",
        "    values.append(predict_list[idx])\n",
        "  #\n",
        "\n",
        "  return names, values\n"
      ],
      "metadata": {
        "id": "axhtDrnIYyjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# check it\n",
        "names, values = foxy.predict_butterfly(image)"
      ],
      "metadata": {
        "id": "bus7QYABb0GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check it\n",
        "print(names, values)"
      ],
      "metadata": {
        "id": "MUeZ5rb-dCeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ven0xo-RSYqR"
      },
      "outputs": [],
      "source": [
        "# val = foxy.predict_butterfly(img_down, foxy.learner)\n",
        "# val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFJTzjbynGJH"
      },
      "outputs": [],
      "source": [
        "# val10 = foxy.make_prediction(img_down, foxy.learner, max=2)\n",
        "# val10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfRuN3n_4ROC"
      },
      "source": [
        "# ðŸ¤–  Donut Graph: ðŸ© (Step 12)\n",
        "\n",
        "**PRIMARY ROLE**: AI Scientist\n",
        "\n",
        "- Love to draw donut graph, all done by ai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhnB0xXLvnvd"
      },
      "outputs": [],
      "source": [
        "# # prompt: extract all the accuracy_score value from top_3\n",
        "\n",
        "# values = [item[\"accuracy_score\"] for item in top3]\n",
        "# names = [item[\"name\"] for item in top3]\n",
        "print(names, values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVyn8xcbL8lA"
      },
      "outputs": [],
      "source": [
        "# %%write -a app.py\n",
        "# prompt: (Gemini and codey)\n",
        "# prompt: use matplotlib to draw a donut graph taking a list as name and list of value as input\n",
        "# prompt: add value to the label in the draw_donut_chart function\n",
        "# prompt: replace the white center of the draw_donut_chart function with an image\n",
        "# prompt: add text line to matplotlib plot bottom left position\n",
        "# prompt: change the draw_donut_graph function to use matplotlib.pyplot.subplots\n",
        "\n",
        "import matplotlib\n",
        "\n",
        "@add_method(Pluto_FastAI)\n",
        "def draw_donut_chart(self, names, values, img_center=None,\n",
        "  title=\"Donut Chart\", figsize=(12, 6), is_show_plot=False):\n",
        "  \"\"\"\n",
        "  Creates a donut chart using Matplotlib, with 4 distinct colors for up to 4 items.\n",
        "\n",
        "  Args:\n",
        "      names (list): A list of names for the slices of the donut chart (max 4).\n",
        "      values (list): A list of numerical values corresponding to the slices.\n",
        "      img_center: (PIL or None) the center image or white blank image.\n",
        "      title (str, optional): The title of the chart. Defaults to \"Donut Chart\".\n",
        "      figsize (tuple, optional): The size of the figure in inches. Defaults to (8, 6).\n",
        "  \"\"\"\n",
        "\n",
        "  total = sum(values)\n",
        "  values = [value / total * 100 for value in values]\n",
        "\n",
        "  fig, ax = matplotlib.pyplot.subplots(figsize=figsize)\n",
        "\n",
        "  # #FF6F61 (coral), #6B5B95 (purple), #88B04B (green), #F7CAC9 (pink)\n",
        "  colors = ['#257180', '#F2E5BF', '#FD8B51', self.color_secondary]  # Define 4 distinct colors\n",
        "  # colors = [self.color_primary, self.color_success, self.color_info, self.color_secondary]\n",
        "  wedges, texts = ax.pie(values, labels=names, wedgeprops=dict(width=0.6), colors=colors[:len(names)])  # Use the first 4 colors\n",
        "  legend_title = [f\"{name} ({value:.2f}%)\" for name, value in zip(names, values)]\n",
        "  ax.legend(wedges, legend_title, loc='best') # was loc=\"upper right\"\n",
        "\n",
        "  # Add an image to the center of the donut chart\n",
        "  # image_path = \"/content/butterfly_img/Monarch460CL.jpg\"\n",
        "  # img = matplotlib.image.imread(image_path)\n",
        "  fig = matplotlib.pyplot.gcf()\n",
        "  if img_center is None:\n",
        "    center_circle = matplotlib.pyplot.Circle((0, 0), 0.4, fc='white', ec='#333333')\n",
        "    ax.add_artist(center_circle)\n",
        "  else:\n",
        "    # img = PIL.Image.open(img_center_path)\n",
        "    ax.imshow(img_center, extent=(-0.5, 0.5, -0.5, 0.5))\n",
        "  t = f\"{title}:\\n{names[0]}, {round(values[0], 2)}% certainty\"\n",
        "  ax.set_title(t, fontsize=16)\n",
        "  ax.set_axis_off()\n",
        "  #\n",
        "  copyw = f\"*{self.author}, [AI] {self.name} (GNU 3.0) 2024\"\n",
        "  ax.text(x=0.05, y=0.05, s=copyw, ha='left', va='bottom',\n",
        "    fontsize=7.0, transform=ax.transAxes)\n",
        "  #\n",
        "  fig.tight_layout()\n",
        "  if (is_show_plot is True):\n",
        "    fig.show()\n",
        "    print(\"show me\")\n",
        "    # plt.show()\n",
        "  return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7oy4iWZL4fB"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# check it\n",
        "canvas = foxy.draw_donut_chart(names, values, img_center=image,\n",
        "  title=\"Top 3 (out of 75) Butterfly CNN Prediction\", is_show_plot=False, figsize=(9,9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbzI7HBpOiKU"
      },
      "outputs": [],
      "source": [
        "# display(canvas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW8Z3V86Tyl1"
      },
      "outputs": [],
      "source": [
        "# canvas = foxy.draw_donut_chart(names, values,\n",
        "#   title=\"Top 3 (out of 75) Butterfly CNN Classification\", is_show_plot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrogFsFP42qT"
      },
      "source": [
        "# ðŸ¤– Gradio (Step 13)\n",
        "\n",
        "**PRIMARY ROLE:** AI Scientist\n",
        "\n",
        "- Use Gradio to stage it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKCVyt2j6CSd"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "import gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gradio.Image?\n",
        "\n",
        "# type: The format the image is converted before being passed into the prediction function. \"numpy\" converts the image to a numpy array with shape (height, width, 3) and values from 0 to 255, \"pil\" converts the image to a PIL image object, \"filepath\" passes a str path to a temporary file containing the image. If the image is SVG, the `type` is ignored and the filepath of the SVG is returned. To support animated GIFs in input, the `type` should be set to \"filepath\" or \"pil\"."
      ],
      "metadata": {
        "id": "cdA21om41N9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print gradio version\n",
        "\n",
        "print(gradio.__version__)\n",
        "# tested with 5.1.0"
      ],
      "metadata": {
        "id": "bU23AQw8q6Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print version of numpy\n",
        "\n",
        "import numpy\n",
        "\n",
        "print(numpy.__version__)\n",
        "# 1.26.4"
      ],
      "metadata": {
        "id": "zoTHmvsLCvug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%write -a app.py\n",
        "# manual\n",
        "\n",
        "# define all components use in Gradio\n",
        "xtitle = \"\"\"\n",
        "ðŸ¦‹ Welcome: Butterfly CNN Image Classification App\n",
        "\n",
        "### Identify 75 Butterfly Species From Photo.\n",
        "\n",
        ">**Requirement Statement:** (From the client) We aim to boost butterfly numbers by creating and maintaining suitable habitats, promoting biodiversity, and implementing conservation measures that protect them from threats such as habitat loss, climate change, and pesticides.\n",
        ">\n",
        ">**Problem Facing:** Butterfly populations are decreasing due to habitat loss, climate change, and pesticides. This issue endangers their diversity and risks essential pollination services, impacting food production and natural environments. We need the **butterfly population count** from around the world to assess the damage.\n",
        ">\n",
        "> This real-world CNN app is from the [\"AI Solution Architect,\" by ELVTR and Duc Haba](https://elvtr.com/course/ai-solution-architect?utm_source=instructor&utm_campaign=AISA&utm_content=linkedin).\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŒ´ Helpful Instruction:\n",
        "\n",
        "1. Take a picture or upload a picture.\n",
        "\n",
        "2. Click the \"Submit\" button.\n",
        "3. View the result on the Donut plot.\n",
        "4. (Optional) Rate the correctness of the identification.\n",
        "\"\"\"\n",
        "xdescription = \"\"\"\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŒ´ Author Note:\n",
        "\n",
        "- The final UI is a sophisticated iOS, Android, and web app developed by the UI team. It may or may not include the donut graph, but they all utilize the same REST input-output JSON API.\n",
        "\n",
        "- *I hope you enjoy this as much as I enjoyed making it.*\n",
        "\n",
        "- **For Fun:** Upload your face picture and see what kind of butterfly you are.\n",
        "\n",
        "---\n",
        "\n",
        "\"\"\"\n",
        "xallow_flagging = \"manual\"\n",
        "xflagging_options = [\"Good\", \"Bad\"]\n",
        "xarticle = \"\"\"\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŒ» About:\n",
        "\n",
        "- Develop by Duc Haba (human) and GenAI partners (2024).\n",
        "  - AI Codey (for help in coding)\n",
        "  - AI GPT-4o (for help in coding)\n",
        "  - AI Copilot (for help in coding)\n",
        "\n",
        "- Python Jupyter Notebook on Google Colab Pro.\n",
        "  - Python 3.10\n",
        "  - 8 CPU Cores (Intel Xeon)\n",
        "  - 60 GB RAM\n",
        "  - 1 GPU (Tesla T4)\n",
        "  - 15 GB GPU RAM\n",
        "  - 254 GB Disk Space\n",
        "\n",
        "- Primary Lib:\n",
        "  - Fastai (2.7.17)\n",
        "- Standard Lib:\n",
        "  - PyTorch\n",
        "  - Gradio\n",
        "  - PIL\n",
        "  - Matplotlib\n",
        "  - Numpy\n",
        "  - Pandas\n",
        "\n",
        "- Dataset (labled butterfly images)\n",
        "  - Kaggle website\n",
        "  - The University of Florida's McGuire Center for Lepidoptera and Biodiversity (United States)\n",
        "\n",
        "- Deployment Model and Hardware:\n",
        "  - Butterfly CNN model (inference engine)\n",
        "  - 2 CPU Cores (Intel Xeon)\n",
        "  - 16 GB RAM\n",
        "  - No GPU\n",
        "  - 16 GB Disk Space\n",
        "  - Virtual container (for scaleability in server-cluster)\n",
        "  - No Data and no other ML or LLM\n",
        "  - Own 100% Intellectual Property\n",
        "\n",
        "---\n",
        "### ðŸ¤” Accuracy and Benchmark\n",
        "\n",
        "**Task:** Indentify 75 type of butterfly species from user taking photo with their iPhone.\n",
        "\n",
        "- **94.1% Accurate**: This Butterfly CNN Image Classification developed by Duc Haba and GenAI friends (Deep Learning, CNN)\n",
        "\n",
        "- **Average 87.5% Accurate**: Lepidopterist (human)\n",
        "\n",
        "- **Less than 50% Accurate**: Generative AI, like Genini or Claude 3.5 (AI)\n",
        "\n",
        "(NOTE: Lepidopterist and GenAI estimate are from online sources and GenAI.)\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ¦‹ KPIs (Key Performance Indicator by Client)\n",
        "\n",
        "\n",
        "1. **AI-Powered Identification:** The app leverages an advanced CNN model to achieve identification accuracy on par with or surpassing that of expert lepidopterists. It quickly and precisely recognizes butterfly species from user-uploaded images, making it an invaluable tool for butterfly enthusiasts, citizen scientists, and researchers.\n",
        "  - Complied. Detail on seperate document.\n",
        "\n",
        "2. **Accessible API for Integration:** We'll expose an API to integrate the AI with mobile and web apps. It will encourage open-source developers to build hooks into existing or new apps.\n",
        "  - Complied. Detail on seperate document.\n",
        "\n",
        "3. **Universal Access:** The Butterfly app is for everyone, from citizens to experts. We want to create a community that cares about conservation.\n",
        "  - Complied. Detail on seperate document.\n",
        "\n",
        "4. **Shared Database for Research:** Our solution includes\n",
        "a shared database that will hold all collected data. It will\n",
        "be a valuable resource for researchers studying butterfly populations, their distribution, and habitat changes. The database will consolidate real-world data to support scientific research and comprehensive conservation planning.\n",
        "  - Complied. Detail on seperate document.\n",
        "\n",
        "5. **Budget and Schedule:** *Withheld.*\n",
        "  - Complied ...mostly :-)\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ¤– The First Law of AI Collaboration:\n",
        "- This CNN Image Classification app development is in compliance with [The First Law of AI Collaboration](https://www.linkedin.com/pulse/first-law-ai-collaboration-duc-haba-hcqkc/)\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŒŸ \"AI Solution Architect\" Course by ELVTR\n",
        "\n",
        ">Welcome to the fascinating world of AI and Convolutional Neural Network (CNN) Image Classification. This CNN model is a part of one of three hands-on application. In our journey together, we will explore the [AI Solution Architect](https://elvtr.com/course/ai-solution-architect?utm_source=instructor&utm_campaign=AISA&utm_content=linkedin) course, meticulously crafted by ELVTR in collaboration with Duc Haba. This course is intended to serve as your gateway into the dynamic and constantly evolving field of AI Solution Architect, providing you with a comprehensive understanding of its complexities and applications.\n",
        "\n",
        ">An AI Solution Architect (AISA) is a mastermind who possesses a deep understanding of the complex technicalities of AI and knows how to creatively integrate them into real-world solutions. They bridge the gap between theoretical AI models and practical, effective applications. AISA works as a strategist to design AI systems that align with business objectives and technical requirements. They delve into algorithms, data structures, and computational theories to translate them into tangible, impactful AI solutions that have the potential to revolutionize industries.\n",
        "\n",
        "> ðŸŽ [Sign up for the course today](https://elvtr.com/course/ai-solution-architect?utm_source=instructor&utm_campaign=AISA&utm_content=linkedin), and I will see you in class.\n",
        "\n",
        "- An article about the Butterfly CNN Image Classification will be coming soon.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ™ˆ Legal:\n",
        "\n",
        "- The intent is to share with Duc's friends and students in the AI Solution Architect course by ELVTR, but for those with nefarious intent, this Butterfly CNN Image Classification is governed by the GNU 3.0 License: https://www.gnu.org/licenses/gpl-3.0.en.html\n",
        "- Author: Copyright (C), 2024 **[Duc Haba](https://linkedin.com/in/duchaba)**\n",
        "---\n",
        "\"\"\"\n",
        "# xinputs = [\"image\"]\n",
        "xinputs = [gradio.Image(type=\"pil\")]\n",
        "xoutputs = [\"plot\"]"
      ],
      "metadata": {
        "id": "jNnNBejCRbwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "uRJCiV3FJScg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_ClsvdR42yd"
      },
      "outputs": [],
      "source": [
        "# %%write -a app.py\n",
        "# prompt: write a python code using gradio for simple hello world app\n",
        "# prompt: show all the possible parameters from gradio Interface function\n",
        "# manual: edit the rest\n",
        "\n",
        "def say_butterfly_name(img):\n",
        "  # check for access\n",
        "  if(is_system_verified() is False):\n",
        "    fname = \"ezirohtuanU metsyS\"[::-1]\n",
        "    names = [fname]\n",
        "    values= [1.0]\n",
        "    return names, values\n",
        "  #\n",
        "  names, values = foxy.predict_butterfly(img)\n",
        "  # add in the other\n",
        "  names.append(\"All Others\")\n",
        "  values.append(1-sum(values))\n",
        "  # #   val.append(item)\n",
        "  xcanvas = foxy.draw_donut_chart(names, values,\n",
        "    img_center=img,\n",
        "    title=\"Top 3 (out of 75) Butterfly CNN Prediction\",\n",
        "    is_show_plot=False,\n",
        "    figsize=(9,9))\n",
        "  return xcanvas\n",
        "#\n",
        "#\n",
        "# theme, \"base, default, glass, soft, monochrome\"\n",
        "app = gradio.Interface(fn=say_butterfly_name,\n",
        "  inputs=xinputs,\n",
        "  outputs=xoutputs,\n",
        "  live=False,\n",
        "  allow_duplication=False,\n",
        "  theme=\"soft\",\n",
        "  title=xtitle,\n",
        "  description=xdescription,\n",
        "  article=xarticle,\n",
        "  allow_flagging=xallow_flagging,\n",
        "  flagging_options=xflagging_options)\n",
        "#\n",
        "inline = True\n",
        "width = \"80%\"\n",
        "height = \"80%\" # 1200\n",
        "# app.launch(share=True)\n",
        "app.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.launch?"
      ],
      "metadata": {
        "id": "Ig_7DgN5DUsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8ITASePYOlT"
      },
      "outputs": [],
      "source": [
        "img4 = PIL.Image.open(val[0][\"file_name\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRGh0o265POm"
      },
      "outputs": [],
      "source": [
        "# prompt: show all the possible parameters from gradio Interface function\n",
        "\n",
        "help(gradio.Interface)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NVl-Mf8GbnS"
      },
      "source": [
        "# ðŸ˜Ž FastAPI (Step 14)\n",
        "\n",
        "**PRIMARY ROLE**: Devops."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfBXzGxaGbnS"
      },
      "outputs": [],
      "source": [
        "# %%pip\n",
        "!pip install fastapi\n",
        "!pip install pydantic\n",
        "!pip install uvicorn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5-x_u-JGbnT"
      },
      "outputs": [],
      "source": [
        "# check info\n",
        "!ls -la ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDp8DI57GbnT"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CarQxJMYGbnT"
      },
      "outputs": [],
      "source": [
        "#\n",
        "import typing\n",
        "import fastapi\n",
        "import pydantic\n",
        "import nest_asyncio\n",
        "\n",
        "# Required to run Uvicorn from within Jupyter Notebook\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Define the Pydantic model for the request body\n",
        "class GreetingInput(pydantic.BaseModel):\n",
        "    name: str\n",
        "\n",
        "# define ask_vet input\n",
        "class vet_input(pydantic.BaseModel):\n",
        "    session: str\n",
        "    func_option: str\n",
        "    is_json: bool\n",
        "\n",
        "# Initialize the FastAPI app\n",
        "app = fastapi.FastAPI()\n",
        "\n",
        "#\n",
        "@app.post(\"/greet/\")\n",
        "async def greet(greeting_input: GreetingInput):\n",
        "    val = {\"message\": f\"Hello, {greeting_input.name}!\"}\n",
        "    return val\n",
        "\n",
        "@app.post(\"/ask_foxy/\")\n",
        "async def ask_foxy(dataload: _input):\n",
        "    indata = {\"session\": dataload.session,\n",
        "      \"func_option\" : dataload.func_option}\n",
        "    val = monty.intake_api(indata)\n",
        "    return val\n",
        "#\n",
        "# examples\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Mmo20qZGrM3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GRiH4mSGbnU"
      },
      "source": [
        "# ðŸ˜Ž Start up fastapi uvicorn (Step 15)\n",
        "\n",
        "**PRIMARY ROLE:** Devops\n",
        "\n",
        "- For notebook testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNrR-PyoGbnU"
      },
      "outputs": [],
      "source": [
        "#\n",
        "import uvicorn\n",
        "# Run the server in a cell. If you're running this in Jupyter Lab or Jupyter Classic,\n",
        "# the server will start in the background and will not block the notebook.\n",
        "def run():\n",
        "    uvicorn.run(app, host=monty.host_name, port=8000, log_level=\"info\", reload=False)\n",
        "#\n",
        "# Since we're in a Jupyter environment, we'll run the server in a background thread.\n",
        "# This is essential; otherwise, the server will block the execution of further cells.\n",
        "import threading\n",
        "thread = threading.Thread(target=run, daemon=True)\n",
        "thread.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB-dUz7pGbnV"
      },
      "source": [
        "## STOP: âœ‹ Deploy to AWS\n",
        "\n",
        "- Don't run the below code cell on the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9g12OoRGbnV"
      },
      "outputs": [],
      "source": [
        "#\n",
        "\n",
        "#\n",
        "# ------------------------\n",
        "# FOR DEPLOYMENT TO DOCKER\n",
        "# ------------------------\n",
        "#\n",
        "# start up uvicorn for api\n",
        "import uvicorn\n",
        "#\n",
        "# the server will start in the background and will not block the notebook.\n",
        "def run():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\", reload=False)\n",
        "#\n",
        "#\n",
        "run()\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHk6ykC5H234"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhTiLDkpGbnW"
      },
      "source": [
        "# ðŸ¤” QA Smoke Test API (Step 16)\n",
        "\n",
        "PRIMARY ROLE: AI QA team\n",
        "\n",
        "- QA the api from notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E736rcFxGbnW"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# test it\n",
        "import requests\n",
        "\n",
        "# Define the URL of the FastAPI endpoint\n",
        "url = f'http://{foxy.host_name}:8000/greet/'\n",
        "\n",
        "# Define the data payload as a dictionary\n",
        "data = {\"name\": \"Duc\"}\n",
        "\n",
        "# Send a POST request\n",
        "response = requests.post(url, json=data)\n",
        "\n",
        "# Print the response JSON content\n",
        "print(response.json())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPiAIy1qGbnW"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# test it\n",
        "# Define the URL of the FastAPI endpoint\n",
        "url = f'http://{foxy.host_name}:8000/ask_foxy/'\n",
        "\n",
        "# Define the data payload as a dictionary\n",
        "dload = {\"session\": \"I am a lost butterfly. Who am I?\",\n",
        "  \"func_option\": \"classification\"}\n",
        "\n",
        "# Send a POST request\n",
        "response = requests.post(url, json=dload)\n",
        "\n",
        "# Print the response JSON content\n",
        "val = response.json()\n",
        "val2 = json.loads(val)\n",
        "val2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzVa1DG4Bnna"
      },
      "source": [
        "- **Negative Path:** âœ‹ Just one bad bean.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Hsu7kLvGbnY"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# test it\n",
        "# Define the URL of the FastAPI endpoint\n",
        "url = f'http://{foxy.host_name}:8000/ask_foxy/'\n",
        "\n",
        "# Define the data payload as a dictionary\n",
        "dload = {\"session\": \"this is a false statement.\",\n",
        "  \"func_option\": \"locky\"}\n",
        "\n",
        "# Send a POST request\n",
        "response = requests.post(url, json=dload)\n",
        "\n",
        "# Print the response JSON content\n",
        "val = response.json()\n",
        "val2 = json.loads(val)\n",
        "val2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oN9qqkTfIHYq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjzAs2Az5afx"
      },
      "source": [
        "# ðŸ˜Ž Deployment (Step 17)\n",
        "\n",
        "**PRIMARY ROLE**: Devops.\n",
        "\n",
        "\n",
        "- Create the app.py and requirement.txt files\n",
        "\n",
        "- Copy them to the folder:\n",
        "    - /deploy\n",
        "    \n",
        "- notify Rodrigo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuU5TqqmfOTZ"
      },
      "source": [
        "**Note:** From\n",
        "\n",
        "**Build and Deploy Process**\n",
        "\n",
        "- **Local Docker Build**\n",
        "\n",
        "    - This step assume you are on â€œdevelopâ€ branch. The kin AI application is located under â€œhttps://github.com/deployâ€ folder which has a Dockerfile to build the application. Incase docker is not installed it can be downloaded from https://www.docker.com/products/docker-desktop/. Run the following command to build it locally\n",
        "\n",
        "    - docker build --tag kinship-ai .\n",
        "    - Once the build is done, the docker can be run using the command\n",
        "    - docker run -p 8000:8000 kinship-ai\n",
        "    - The application should be accessible at http://localhost:8000\n",
        "\n",
        "- **Build and Deploy on AWS**\n",
        "\n",
        "    - To deploy on AWS changes from â€œdevelop\" branch should be promoted to \"staging\" branch, and that can be done by creating and merging a PR on GitHub from â€œdevelopâ€ to â€œstagingâ€. Once the changes are merged, they CICD deployment pipeline will create a container and deploy onto EKS environment in AWS. This step should not take more than 5 mins. Sample curl command to test\n",
        "\n",
        "curl --location 'https://ai.com/greet/' \\\n",
        "--header 'Content-Type: application/json' \\\n",
        "--data '{\"name\":\"Duc\"}'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EBZUnjiGbnZ"
      },
      "source": [
        "## Back up\n",
        "\n",
        "- **STOP**: Go and do Git pull and push (section) below.\n",
        "\n",
        "- We need to know if we are clean and ready to rock and roll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GdSYLOHSv7b"
      },
      "outputs": [],
      "source": [
        "# # prompt: Add in a parameter to print the result to a file with the same name as the notebook but with .py file extention\n",
        "\n",
        "# import json\n",
        "\n",
        "# def print_code_cells_from_notebook(notebook_name, filter_magic=\"# %%write\", write_to_file=True, fname_override=None):\n",
        "#     \"\"\"\n",
        "#     Reads a Jupyter notebook (.ipynb file) and writes out all the code cells\n",
        "#     that start with the specified magic command to a .py file.\n",
        "\n",
        "#     Parameters:\n",
        "#     - notebook_name (str): Name of the notebook file (with .ipynb extension).\n",
        "#     - filter_magic (str): Magic command filter. Only cells starting with this command will be written.\n",
        "#         The defualt is: \"# %%write\"\n",
        "#     - write_to_file (bool): If True, writes the filtered cells to a .py file.\n",
        "#         Otherwise, prints them to the standard output. The default is True.\n",
        "#     - fname_override (str): If provided, overrides the output filename. The default is None.\n",
        "\n",
        "#     Returns:\n",
        "#     - None: Writes the filtered code cells to a .py file or prints them based on the parameters.\n",
        "\n",
        "#     \"\"\"\n",
        "#     with open(notebook_name, 'r', encoding='utf-8') as f:\n",
        "#       notebook_content = json.load(f)\n",
        "\n",
        "#     output_content = []\n",
        "\n",
        "#     # Loop through all the cells in the notebook\n",
        "#     for cell in notebook_content['cells']:\n",
        "#       # Check if the cell type is 'code' and starts with the specified magic command\n",
        "#       if cell['cell_type'] == 'code' and cell['source'] and cell['source'][0].startswith(filter_magic):\n",
        "#         # Append the source code of the cell to output_content\n",
        "#         output_content.append(''.join(cell['source']))\n",
        "\n",
        "#     if write_to_file:\n",
        "#       if fname_override is None:\n",
        "#         # Derive the output filename by replacing .ipynb with .py\n",
        "#         output_filename = notebook_name.replace(\".ipynb\", \".py\")\n",
        "#       else:\n",
        "#         output_filename = fname_override\n",
        "#       with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "#         f.write('\\n'.join(output_content))\n",
        "#       print(f'File: {output_filename} written to disk.')\n",
        "#     else:\n",
        "#       # Print the code cells to the standard output\n",
        "#       print('\\n'.join(output_content))\n",
        "#       print('-' * 40)  # print separator\n",
        "\n",
        "# # Example usage:\n",
        "# # print_code_cells_from_notebook('your_notebook_name_here.ipynb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azIVxAI8Gbna"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvPkehM4fOWW"
      },
      "outputs": [],
      "source": [
        "# make a copy so we can roll back\n",
        "import os\n",
        "if not os.path.exists('save_me_'):\n",
        "  os.makedirs('save_me')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgoyZmYMfOZ9"
      },
      "outputs": [],
      "source": [
        "!ls -la {q2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvJq3LHxfOco"
      },
      "outputs": [],
      "source": [
        "# save it\n",
        "\n",
        "!cp {q2}app.py {q1}\n",
        "!cp {q2}Dockerfile {q1}\n",
        "!cp {q2}requirements.txt {q1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbNUGvxiGbnb"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-BI8N3kGbnc"
      },
      "outputs": [],
      "source": [
        "!git branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YjGJDzzGbnc"
      },
      "outputs": [],
      "source": [
        "# check for diff\n",
        "src = \"app.py\"\n",
        "!git diff origin/develop...HEAD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNzBde3mfOqV"
      },
      "source": [
        "## app.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-u2-pYMGbnc"
      },
      "outputs": [],
      "source": [
        "# q1 = \"/duc/\"\n",
        "# !ls -la {q1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4i5fVXifOtd"
      },
      "outputs": [],
      "source": [
        "# get all write file\n",
        "# this file:\n",
        "fname = \"./AISA_Solution_arch_butterfly_2024_image_classification.ipynb\"\n",
        "foxy.fetch_code_cells(fname, write_to_file=True,\n",
        "  fname_override='app_p2.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-R_NHQ-fRhs"
      },
      "source": [
        "**STOP**\n",
        "\n",
        "Manual edit the app_p2.py for:\n",
        "\n",
        "1. fname_req = './requirements.txt'\n",
        "\n",
        "2. monty._gpt_crkey =\n",
        "\n",
        "2. **Double check** on the uvicorn start up\n",
        "\n",
        "2. **Double check** for missing code that should not be deploy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbxbOXizfRkw"
      },
      "outputs": [],
      "source": [
        "# create the app.py\n",
        "p1 = \"/content/pluto_happy/pluto_foxy.py\"\n",
        "p2 = \"app_p2.py\"\n",
        "p3 = \"app.py\"\n",
        "!cat {p1} {p2} > {p3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqIRw75zfRnc"
      },
      "outputs": [],
      "source": [
        "# check it\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fMMc1YUfRqR"
      },
      "source": [
        "**Double check**\n",
        "\n",
        "- Manual review the app.py file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xN8VEhA6yeh"
      },
      "source": [
        "## requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKpT0aLoGbnf"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fname = \"/content/pluto_happy/requirements_foxy.txt\"\n",
        "!cat {fname}"
      ],
      "metadata": {
        "id": "nlkU-iadhhCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp {fname} requirements.txt"
      ],
      "metadata": {
        "id": "7WrpHuaUhhF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print numpy version\n",
        "\n",
        "print(numpy.__version__)\n",
        "# 1.26.4"
      ],
      "metadata": {
        "id": "roB93Z69hhJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSdDpwmD6ynw"
      },
      "outputs": [],
      "source": [
        "!cp {q2}requirements.txt {q1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U220d0lY6yq3"
      },
      "outputs": [],
      "source": [
        "# view it\n",
        "!cat {q1}requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba234qGS6zJf"
      },
      "outputs": [],
      "source": [
        "help(monty.fetch_code_cells_from_notebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWL5WQny6zF1"
      },
      "outputs": [],
      "source": [
        "# get all pip file\n",
        "# this file:\n",
        "fname = \"v7.ipynb\"\n",
        "monty.fetch_code_cells_from_notebook(fname, write_to_file=False, filter_magic=\"# %%pip\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXSLuWb5Gbnh"
      },
      "source": [
        "- **STOP**: Manually double check requirements.txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcHuFYnJGbni"
      },
      "outputs": [],
      "source": [
        "!cat requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3tO7lq9Gbni"
      },
      "source": [
        "## Docker\n",
        "\n",
        "- Generally we don't edit this file unless there is new artifact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuD2lLCjGbni"
      },
      "outputs": [],
      "source": [
        "# copy what was there\n",
        "q1 = \"/huma/\"\n",
        "q2 = \"//deploy/\"\n",
        "!cp {q2}Dockerfile {q1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mue3UV2DGbnj"
      },
      "outputs": [],
      "source": [
        "# check it\n",
        "!cat {q1}Dockerfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOEQIBC2Gbnj"
      },
      "source": [
        "- **STOP**: manual edit to include the artifact in index_kin_all640_article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOmmNWwRGbnj"
      },
      "outputs": [],
      "source": [
        "# check again after manual edit\n",
        "!cat {q1}Dockerfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQkPhDd9Gbnk"
      },
      "source": [
        "## Deploy/copy to deploy_now\n",
        "\n",
        "The 4 files and folder are:\n",
        "\n",
        "1. app.py\n",
        "2. requirements.txt\n",
        "3. Dockerfile\n",
        "4. artifact \"index_kin_all640_article\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Musg_y5oGbnk"
      },
      "outputs": [],
      "source": [
        "# copy\n",
        "q1 = \"duc\"\n",
        "q2 = \"deploy\"\n",
        "q3 = \"queen/\"\n",
        "#\n",
        "!cp {q1}app.py {q2}\n",
        "!cp {q1}requirements.txt {q2}\n",
        "!cp {q1}Dockerfile {q2}\n",
        "!cp -R {q3} {q2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue_XXHraGbnk"
      },
      "outputs": [],
      "source": [
        "# check it\n",
        "!ls -la {q2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BS9SoFGWGbnl"
      },
      "outputs": [],
      "source": [
        "# check it\n",
        "!ls -la {q2}index_kin_all640_article/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMkbEOyMGbnl"
      },
      "outputs": [],
      "source": [
        "# check it\n",
        "!cat {q2}requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3twD5VTsGbnl"
      },
      "outputs": [],
      "source": [
        "# check it\n",
        "!cat {q2}Dockerfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W40jUesZGbnn"
      },
      "source": [
        "**STOP**: Manually commit and push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9a_8Vc9IcD-"
      },
      "outputs": [],
      "source": [
        "!curl --location 'https://foxy.com/greet/' \\\n",
        "--header 'Content-Type: application/json' \\\n",
        "--data '{\"name\":\"It was a ship and not a sheep.\"}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHDzAHjoIkaK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0BqlE3dGbnq"
      },
      "source": [
        "# ðŸ˜Ž GitHub (Step 18)\n",
        "\n",
        "**PRIMARY ROLE**: Devops.\n",
        "\n",
        "**Note:** âœ‹\n",
        "\n",
        "- QA it on this notebook **BEFORE** push it.\n",
        "\n",
        "- If you change any data or files, commit and push it to github. For now, we don't need pull-request, so push it to main or your-branch-name.\n",
        "\n",
        "- I ussualy comment out the section because I don't want to accidental run it (when not ready)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIVSHSwmGbnq"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iytF4it5eCt3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "f = 'pluto_happy'\n",
        "# f = '/content/foxy_cnn_image_classification'\n",
        "os.chdir(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBESQ2AAGbnq"
      },
      "outputs": [],
      "source": [
        "!git branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlvaEHrEGbnr"
      },
      "outputs": [],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKnWWmInGbnr"
      },
      "outputs": [],
      "source": [
        "# check for update file\n",
        "!git diff --name-only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWTzuEkld8E6"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# f = 'Data-Augmentation-with-Python'\n",
        "# os.chdir(f)\n",
        "!git add -A\n",
        "!git config --global user.email \"duc.haba@gmail.com\"\n",
        "!git config --global user.name \"duchaba\"\n",
        "!git commit -m \"add new predict methods\"\n",
        "# # do the git push in the xterm console\n",
        "# #!git push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMDuDF5gGbnr"
      },
      "outputs": [],
      "source": [
        "# # check for any in stage ready to commit\n",
        "# !git diff --name-only --staged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAIl7ZzEGbns"
      },
      "outputs": [],
      "source": [
        "# check what were the commits\n",
        "!git log --name-status HEAD^..HEAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Azo-O8pGbnt"
      },
      "outputs": [],
      "source": [
        "# double check it before commit\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmPsmXZBuaB3"
      },
      "outputs": [],
      "source": [
        "!pip install lfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fU6cc4f4ulGZ"
      },
      "outputs": [],
      "source": [
        "# prompt: git push large file\n",
        "\n",
        "!git-lfs track *.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWaoO8u2Gbnt"
      },
      "outputs": [],
      "source": [
        "# push it\n",
        "fname = \"https://duchaba:@github.com/duchaba/pluto_happy.git\"\n",
        "!git push {fname}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agentic AI, use Gemini to find if it a butterfly"
      ],
      "metadata": {
        "id": "lF8b4zZDZ0Kn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwmVp4GakGx1"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a python function using Google AI on Jupyter Notebook to check if the upload image is a butterfuly or not.\n",
        "\n",
        "import base64\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Before running, make sure you have the 'requests' library installed:\n",
        "# !pip install requests\n",
        "\n",
        "def is_image_a_butterfly(image_path: str, api_key: str) -> None:\n",
        "    \"\"\"\n",
        "    Analyzes an image using the Gemini API to determine if it contains a butterfly.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): The file path to the image you want to analyze.\n",
        "        api_key (str): Your Google Cloud Gemini API key.\n",
        "    \"\"\"\n",
        "    # Check if the image file exists\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Error: The file at '{image_path}' was not found.\")\n",
        "        return\n",
        "\n",
        "    # Display the image in the notebook for context\n",
        "    print(\"Analyzing this image:\")\n",
        "    display(Image(filename=image_path))\n",
        "\n",
        "    # Read the image file and convert it to base64\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading image file: {e}\")\n",
        "        return\n",
        "\n",
        "    # Define the API endpoint and the model to use\n",
        "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key={api_key}\"\n",
        "\n",
        "    # Set up the prompt for the model\n",
        "    prompt = \"Is this image a butterfly? Respond with only 'yes' or 'no'.\"\n",
        "\n",
        "    # Construct the request payload\n",
        "    payload = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [\n",
        "                    {\"text\": prompt},\n",
        "                    {\n",
        "                        \"inlineData\": {\n",
        "                            \"mimeType\": \"image/jpeg\",  # Adjust mimeType if your image is not a JPEG\n",
        "                            \"data\": image_data\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"generationConfig\": {\n",
        "            \"responseMimeType\": \"application/json\",\n",
        "            \"responseSchema\": {\n",
        "                \"type\": \"OBJECT\",\n",
        "                \"properties\": {\n",
        "                    \"isButterfly\": {\n",
        "                        \"type\": \"STRING\"\n",
        "                    }\n",
        "                },\n",
        "                \"propertyOrdering\": [\"isButterfly\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Make the API call with exponential backoff\n",
        "    max_retries = 5\n",
        "    retry_delay = 1\n",
        "    for i in range(max_retries):\n",
        "        try:\n",
        "            print(\"Sending request to Gemini API...\")\n",
        "            response = requests.post(url, json=payload)\n",
        "            response.raise_for_status() # Raise an exception for bad status codes\n",
        "            result = response.json()\n",
        "\n",
        "            # Extract the generated text from the response\n",
        "            if result.get(\"candidates\"):\n",
        "                response_text = result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "                response_json = json.loads(response_text)\n",
        "                print(f\"The model's response is: {response_json['isButterfly']}\")\n",
        "            else:\n",
        "                print(\"The API response did not contain a valid candidate.\")\n",
        "\n",
        "            break # Break the loop if successful\n",
        "\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            if e.response.status_code == 429 and i < max_retries - 1:\n",
        "                print(f\"Rate limit exceeded. Retrying in {retry_delay} seconds...\")\n",
        "                time.sleep(retry_delay)\n",
        "                retry_delay *= 2\n",
        "            else:\n",
        "                print(f\"An HTTP error occurred: {e}\")\n",
        "                print(f\"Response body: {e.response.text}\")\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}\")\n",
        "            break\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example Usage ---\n",
        "\n",
        "# 1. Replace with your actual API key\n",
        "# You can get one from the Google Cloud console.\n",
        "API_KEY = os.environ['google_key']\n",
        "\n",
        "# 2. Provide the path to your image file\n",
        "# For this example, let's assume you have a file named 'butterfly.jpg'\n",
        "# in the same directory as your notebook.\n",
        "IMAGE_FILE_PATH = \"/content/5184.png\"\n",
        "\n",
        "# 3. Call the function\n",
        "is_image_a_butterfly(IMAGE_FILE_PATH, API_KEY)"
      ],
      "metadata": {
        "id": "GlloDVxNbyBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# --- Example Usage ---\n",
        "\n",
        "# # 1. Replace with your actual API key\n",
        "# # You can get one from the Google Cloud console.\n",
        "# API_KEY = \"AIzaSyCNOlrExlI-SgqCHHqnOqjjxaNJxgWcy6U\"\n",
        "\n",
        "# 2. Provide the path to your image file\n",
        "# For this example, let's assume you have a file named 'butterfly.jpg'\n",
        "# in the same directory as your notebook.\n",
        "IMAGE_FILE_PATH = \"/content/Duc_Haba_Oct_2024_square_small.png\"\n",
        "\n",
        "# 3. Call the function\n",
        "is_image_a_butterfly(IMAGE_FILE_PATH, API_KEY)"
      ],
      "metadata": {
        "id": "5wi1ADXPZWSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Write a python function using Google AI on Jupyter Notebook to check what is the butterfly species of the upload butterfly image.\n",
        "\n",
        "import base64\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Before running, make sure you have the 'requests' library installed:\n",
        "# !pip install requests\n",
        "google_key = os.environ['google_key']\n",
        "def identify_butterfly_species(image_path: str, api_key =google_key) -> None:\n",
        "    \"\"\"\n",
        "    Analyzes an image using the Gemini API to identify the butterfly species.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): The file path to the image you want to analyze.\n",
        "        api_key (str): Your Google Cloud Gemini API key.\n",
        "    \"\"\"\n",
        "    # Check if the image file exists\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Error: The file at '{image_path}' was not found.\")\n",
        "        return\n",
        "\n",
        "    # Display the image in the notebook for context\n",
        "    print(\"Analyzing this image:\")\n",
        "    display(Image(filename=image_path))\n",
        "\n",
        "    # Read the image file and convert it to base64\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            # Determine mimeType based on file extension\n",
        "            if image_path.lower().endswith(('.png', '.gif')):\n",
        "                mime_type = \"image/png\"\n",
        "            else:\n",
        "                mime_type = \"image/jpeg\"\n",
        "\n",
        "            image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading image file: {e}\")\n",
        "        return\n",
        "\n",
        "    # Define the API endpoint and the model to use\n",
        "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key={api_key}\"\n",
        "\n",
        "    # Set up the new prompt for the model\n",
        "    prompt = \"Identify the species of the butterfly in this image. If you cannot identify it, state 'Unknown'.\"\n",
        "\n",
        "    # Construct the request payload\n",
        "    payload = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [\n",
        "                    {\"text\": prompt},\n",
        "                    {\n",
        "                        \"inlineData\": {\n",
        "                            \"mimeType\": mime_type,\n",
        "                            \"data\": image_data\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"generationConfig\": {\n",
        "            \"responseMimeType\": \"application/json\",\n",
        "            \"responseSchema\": {\n",
        "                \"type\": \"OBJECT\",\n",
        "                \"properties\": {\n",
        "                    \"species\": {\n",
        "                        \"type\": \"STRING\"\n",
        "                    }\n",
        "                },\n",
        "                \"propertyOrdering\": [\"species\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Make the API call with exponential backoff\n",
        "    max_retries = 5\n",
        "    retry_delay = 1\n",
        "    for i in range(max_retries):\n",
        "        try:\n",
        "            print(\"Sending request to Gemini API...\")\n",
        "            response = requests.post(url, json=payload)\n",
        "            response.raise_for_status() # Raise an exception for bad status codes\n",
        "            result = response.json()\n",
        "\n",
        "            # Extract the generated text from the response\n",
        "            if result.get(\"candidates\"):\n",
        "                response_text = result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "                response_json = json.loads(response_text)\n",
        "                print(f\"The model identified the species as: {response_json['species']}\")\n",
        "            else:\n",
        "                print(\"The API response did not contain a valid candidate.\")\n",
        "\n",
        "            break # Break the loop if successful\n",
        "\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            if e.response.status_code == 429 and i < max_retries - 1:\n",
        "                print(f\"Rate limit exceeded. Retrying in {retry_delay} seconds...\")\n",
        "                time.sleep(retry_delay)\n",
        "                retry_delay *= 2\n",
        "            else:\n",
        "                print(f\"An HTTP error occurred: {e}\")\n",
        "                print(f\"Response body: {e.response.text}\")\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}\")\n",
        "            break\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n",
        "# 1. Replace with your actual API key\n",
        "# You can get one from the Google Cloud console.\n",
        "#API_KEY = \"YOUR_API_KEY_HERE\"\n",
        "\n",
        "# 2. Provide the path to your image file\n",
        "# For this example, let's assume you have a file named 'monarch.jpg'\n",
        "# in the same directory as your notebook.\n",
        "IMAGE_FILE_PATH = \"monarch.jpg\"\n",
        "\n",
        "# 3. Call the function\n",
        "# identify_butterfly_species(IMAGE_FILE_PATH, API_KEY)\n"
      ],
      "metadata": {
        "id": "0lqrCwRncWEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# --- Example Usage ---\n",
        "\n",
        "# 1. Replace with your actual API key\n",
        "# You can get one from the Google Cloud console.\n",
        "# API_KEY = \"AIzaSyCNOlrExlI-SgqCHHqnOqjjxaNJxgWcy6U\"\n",
        "\n",
        "# 2. Provide the path to your image file\n",
        "# For this example, let's assume you have a file named 'monarch.jpg'\n",
        "# in the same directory as your notebook.\n",
        "IMAGE_FILE_PATH = \"/content/5184.png\"\n",
        "\n",
        "# 3. Call the function\n",
        "identify_butterfly_species(IMAGE_FILE_PATH)"
      ],
      "metadata": {
        "id": "zGJ4vjOXcWR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1385f8a"
      },
      "source": [
        "import gradio as gr\n",
        "import base64\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "import time # Import time for exponential backoff\n",
        "\n",
        "# Assuming identify_butterfly_species function is defined in a previous cell\n",
        "\n",
        "# Define the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=lambda image_file: identify_butterfly_species(image_file),\n",
        "    inputs=gr.Image(type=\"filepath\", label=\"Upload Butterfly Image\"), # Accept image file path\n",
        "    outputs=gr.Textbox(label=\"Identified Species\"), # Output the identified species as text\n",
        "    title=\"Butterfly Species Identifier\",\n",
        "    description=\"Upload an image of a butterfly and the model will attempt to identify its species.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(debug=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF8IisUcb34G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2x-NQlhNSD9"
      },
      "source": [
        "# ðŸ¤  Conclusion (Step 19)\n",
        "\n",
        "**Project finding and summary:**\n",
        "\n",
        "- Have fun coding CNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VL5egEhI16n"
      },
      "outputs": [],
      "source": [
        "foxy.print_dancing()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # @title Choose a different model\n",
        "# from google.colab import ai\n",
        "\n",
        "# response = ai.generate_text(\"What is the capital of England\", model_name='google/gemini-2.0-flash-lite')\n",
        "# print(response)"
      ],
      "metadata": {
        "id": "cyKFGEoMY1AP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "oI7rtNcv2I2u"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}